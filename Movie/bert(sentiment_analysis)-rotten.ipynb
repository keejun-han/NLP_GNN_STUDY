{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c770538e-13b1-4954-ba23-822b574380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from utils import (\n",
    "    tokenizer_setting,\n",
    "    preprocessing,\n",
    "    GPU_setting,\n",
    "    hyperparmeter_setting,\n",
    "    flat_accuracy,\n",
    "    format_time,\n",
    "    initial_setting,\n",
    "    run_train,\n",
    "    run_test,\n",
    "    convert_input_data,\n",
    "    test_sentence_unit,\n",
    "    test_sentence_many\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f02b1-10d6-4b02-ae3d-b6442005cbc3",
   "metadata": {},
   "source": [
    "### 1. Initial Setting\n",
    "- Load the data\n",
    "- Split train, test data\n",
    "- Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9c73c3-f594-4455-8e55-ae8fa90514c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions.csv',\n",
       " 'sampleSubmission.csv',\n",
       " 'test.tsv',\n",
       " 'test.tsv.zip',\n",
       " 'train.tsv',\n",
       " 'train.tsv.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './../../data/rotten_tomato/sentiment_analysis_data/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db002eaf-ab84-4612-a514-90b6823486ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path + 'train.tsv', sep=\"\\t\")\n",
    "test_df = pd.read_csv(path + 'test.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ff6b97-f19b-4004-88c7-8b2b05d6a779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55de2a5-3389-4c8b-9c94-cfa96117722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf79055-824e-4d2f-8fe4-7b68cedf1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['Phrase']\n",
    "y_train = train_df['Sentiment']\n",
    "\n",
    "X_test  = test_df['Phrase']\n",
    "y_test = pd.read_csv(path + 'predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59691c48-a372-4263-b2a6-62cb397c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(feature_df, \n",
    "#                                                     target_df, \n",
    "#                                                     test_size=0.3, \n",
    "#                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c93d42e-6847-4c7f-9c0d-aab2fe2a5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2d1ab-edf5-4008-bbaf-72696b64909b",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4654dd-7eda-4ef7-bd37-e776ce1b0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader, validation_dataloader = preprocessing(X_train.review_content, y_train, tokenizer, process_type='train')\n",
    "train_dataloader, validation_dataloader = preprocessing(X_train, y_train, tokenizer, process_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "634e3b3c-c9d7-4a25-96d6-af4ca5d3b41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = preprocessing(X_test.review_content, y_test, tokenizer, process_type='test')\n",
    "test_dataloader = preprocessing(X_test, y_test, tokenizer, process_type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02560d9-c9e8-435f-9dcd-e4fe99a0ac08",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6564be32-43de-4b24-b6f1-23d49bb9e563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\user\\anaconda3\\envs\\torch37\\lib\\site-packages\\torch\\cuda\\__init__.py:106: UserWarning: \n",
      "NVIDIA GeForce RTX 3080 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3080 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading took: 0:51:40\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels = 5) #label개수에 따라 변경\n",
    "model.cuda()\n",
    "print(\"  Loading took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56441de3-2d8c-4d91-b7c5-89f51084049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device 0 : NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "device = GPU_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1907ef-3070-45fa-97e6-3a21832b55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, epochs, total_steps, scheduler = hyperparmeter_setting(model, train_dataloader, lr=2e-5, eps=1e-8, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "934fb112-0be2-4ca4-9335-65dc4c451bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initial_setting(model, seed_val=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240d427-a054-4790-8461-8e3e724ba180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce5c759a-4f05-46da-97aa-524a52eed31f",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8847067f-60f6-4a89-8e94-15c464d4c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, path, file_name='checkpoint.pth.tar'):\n",
    "    file_path = path + file_name\n",
    "    print(f\"file_path: {file_path}\")\n",
    "    torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d98e7f1-8bcb-47bf-8daf-6bc5f0087dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, epochs, train_dataloader, validation_dataloader, optimizer, scheduler, device, path):\n",
    "    first_start_time = time.time()\n",
    "    \n",
    "    # 에폭 수만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               1. Training\n",
    "        # ========================================\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 로스 초기화\n",
    "        total_loss = 0\n",
    "\n",
    "        # 훈련모드로 변경\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # 경과 정보 표시 (step 500번마다 출력)\n",
    "            if step % 500 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - start_time)\n",
    "                print('Batch {:>5,}  of  {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # 배치를 GPU에 올림\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            # 배치에서 데이터 추출 (input, mask, label 순으로 넣었었음)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                           token_type_ids=None,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # 로스 구함\n",
    "            loss = outputs.loss # outputs[0]\n",
    "\n",
    "            # 총 로스 계산\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward 수행으로 그래디언트 계산 (Back-propagation)\n",
    "            loss.backward()\n",
    "\n",
    "            # 그래디언트 클리핑\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0) # 예제 코드에서는 1.0이었음\n",
    "\n",
    "            # 그래디언트를 이용해 가중치 파라미터를 lr만큼 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "            # 스케줄러로 학습률 감소\n",
    "            scheduler.step()\n",
    "\n",
    "            # 그래디언트 초기화\n",
    "            ## (호출시 경사값을 0으로 설정. 이유 : 반복 때마다 기울기를 새로 계산하기 때문)\n",
    "            model.zero_grad()\n",
    "\n",
    "        # 1 에폭이 끝나면 평균 train 로스 계산 (전체 loss / 배치 수)\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))\n",
    "        \n",
    "        # 체크포인트 저장\n",
    "        print(\"  Model Checkpoint Save\")\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict()\n",
    "            }, path)\n",
    "        \n",
    "        # ========================================\n",
    "        #               2. Validation\n",
    "        # ========================================\n",
    "\n",
    "        # 1 에폭이 끝나면 validation 시행\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 평가 모드로 변경\n",
    "        model.eval()\n",
    "\n",
    "        # 변수 초기화\n",
    "        total_valid_accuracy = 0\n",
    "        nb_valid_steps = 0\n",
    "\n",
    "        # valid 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # 그래디언트 계산 안함!\n",
    "            with torch.no_grad():\n",
    "                # Forward 수행\n",
    "                outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # 로스 구함 (train할 때는 loss, validation할 때는 logits)\n",
    "            ## logits은 softmax를 거치기 전의 classification score를 반환합니다. shape: (batch_size, config.num_labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # CPU로 데이터 이동\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "            valid_accuracy = flat_accuracy(logits, label_ids)\n",
    "            total_valid_accuracy += valid_accuracy\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(total_valid_accuracy/len(validation_dataloader)))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - start_time)))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Total took: {:}\".format(format_time(time.time() - first_start_time)))\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c355ec4a-dc64-4159-b08e-f992f42b9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d944acc-8a08-4989-8093-c9e086ecfb4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "Batch   500  of  4,390. Elapsed: 0:07:58.\n",
      "Batch 1,000  of  4,390. Elapsed: 0:15:56.\n",
      "Batch 1,500  of  4,390. Elapsed: 0:23:55.\n",
      "Batch 2,000  of  4,390. Elapsed: 0:31:53.\n",
      "Batch 2,500  of  4,390. Elapsed: 0:39:52.\n",
      "Batch 3,000  of  4,390. Elapsed: 0:47:51.\n",
      "Batch 3,500  of  4,390. Elapsed: 0:55:51.\n",
      "Batch 4,000  of  4,390. Elapsed: 1:03:50.\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epoch took: 1:10:04\n",
      "  Model Checkpoint Save\n",
      "file_path: ./../../data/rotten_tomato/sentiment_analysis_data/checkpoint.pth.tar\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation took: 0:02:31\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "Batch   500  of  4,390. Elapsed: 0:07:59.\n",
      "Batch 1,000  of  4,390. Elapsed: 0:15:57.\n",
      "Batch 1,500  of  4,390. Elapsed: 0:23:59.\n",
      "Batch 2,000  of  4,390. Elapsed: 0:31:59.\n",
      "Batch 2,500  of  4,390. Elapsed: 0:39:57.\n",
      "Batch 3,000  of  4,390. Elapsed: 0:47:55.\n",
      "Batch 3,500  of  4,390. Elapsed: 0:55:54.\n",
      "Batch 4,000  of  4,390. Elapsed: 1:03:52.\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epoch took: 1:10:05\n",
      "  Model Checkpoint Save\n",
      "file_path: ./../../data/rotten_tomato/sentiment_analysis_data/checkpoint.pth.tar\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation took: 0:02:31\n",
      "\n",
      "Total took: 2:25:19\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model = run_train(model, epochs, train_dataloader, validation_dataloader, optimizer, scheduler, device, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770509dc-eb47-47d1-9e53-299b609ecc3a",
   "metadata": {},
   "source": [
    "### 5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32564ce8-42f9-4a84-8d87-d2e664880b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./../../data/rotten_tomato/sentiment_analysis_data/model_new.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2b77020-5bf3-443c-a377-5768943d46dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./../../data/rotten_tomato/sentiment_analysis_data/model_new.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a88ef561-c4f7-4783-98c8-bd13a84a9b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./../../data/rotten_tomato/sentiment_analysis_data//model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./../../data/rotten_tomato/sentiment_analysis_data//model_save/tokenizer_config.json',\n",
       " './../../data/rotten_tomato/sentiment_analysis_data//model_save/special_tokens_map.json',\n",
       " './../../data/rotten_tomato/sentiment_analysis_data//model_save/vocab.txt',\n",
       " './../../data/rotten_tomato/sentiment_analysis_data//model_save/added_tokens.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = path + '/model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc65a0-0b7f-4a84-8595-852be17a5177",
   "metadata": {},
   "source": [
    "- Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1ba6fd-2ba8-4790-8ac4-6caf560fd947",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model_new = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model_new.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a418ae3-e60c-4c7f-87d7-a0b65a585db0",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4239e0d0-cfd3-481c-b91f-ffa97fbabf63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  2,072.    Elapsed: 0:00:31.\n",
      "  Batch   200  of  2,072.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  2,072.    Elapsed: 0:01:33.\n",
      "  Batch   400  of  2,072.    Elapsed: 0:02:04.\n",
      "  Batch   500  of  2,072.    Elapsed: 0:02:35.\n",
      "  Batch   600  of  2,072.    Elapsed: 0:03:07.\n",
      "  Batch   700  of  2,072.    Elapsed: 0:03:38.\n",
      "  Batch   800  of  2,072.    Elapsed: 0:04:09.\n",
      "  Batch   900  of  2,072.    Elapsed: 0:04:40.\n",
      "  Batch 1,000  of  2,072.    Elapsed: 0:05:11.\n",
      "  Batch 1,100  of  2,072.    Elapsed: 0:05:42.\n",
      "  Batch 1,200  of  2,072.    Elapsed: 0:06:13.\n",
      "  Batch 1,300  of  2,072.    Elapsed: 0:06:44.\n",
      "  Batch 1,400  of  2,072.    Elapsed: 0:07:15.\n",
      "  Batch 1,500  of  2,072.    Elapsed: 0:07:47.\n",
      "  Batch 1,600  of  2,072.    Elapsed: 0:08:18.\n",
      "  Batch 1,700  of  2,072.    Elapsed: 0:08:49.\n",
      "  Batch 1,800  of  2,072.    Elapsed: 0:09:20.\n",
      "  Batch 1,900  of  2,072.    Elapsed: 0:09:51.\n",
      "  Batch 2,000  of  2,072.    Elapsed: 0:10:22.\n",
      "\n",
      "Accuracy: 0.00\n",
      "Test took: 0:10:44\n"
     ]
    }
   ],
   "source": [
    "run_test(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4e5e-56db-46b0-91d4-7ba225fa5e52",
   "metadata": {},
   "source": [
    "- 단일 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "539a5aba-dde1-46a1-bdff-608a9f2c582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2830503   0.88501155  1.9611655   0.79271895 -2.2359402 ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Whether audiences will get behind The Lightning Thief is hard to predict. Overall, it's an entertaining introduction to a promising new world -- but will the consuming shadow of Potter be too big to break free of?\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81f76044-7c2c-4d96-bd71-1cb8d03f4968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6430689  1.9484456  2.4080408 -0.0287358 -3.7612092]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"First section is good, but last is bad.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af73efe5-f76a-4255-b380-e92c7f5b2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.9206464  0.8533373  3.7433295  0.5404129 -3.777921 ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's so so.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab1034e0-a010-49a0-8eb6-489e84f6423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.0808206  1.6647725 -0.7382681 -2.6888063 -1.8536644]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is terrible.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c6959ae6-e6b9-4487-9e1e-60221f7c44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence_unit(model, device, tokenizer, sentence):\n",
    "        \n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(tokenizer, sentence)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783c3a2-7774-46fb-97f9-73b888992d44",
   "metadata": {},
   "source": [
    "- 여러 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bec74c6-55b2-4e3e-9f57-2af65950875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = './../../data/rotten_tomato/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aaa68f7-e1e4-48c8-bec6-9c7f545a2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(path2+'rotten_rating_review_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dfc681b8-57d9-4aa6-b30e-9402ab248875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>origin_index</th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7242</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4895</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jordan Hoffman</td>\n",
       "      <td>False</td>\n",
       "      <td>UGO</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4517</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  origin_index rotten_tomatoes_link       critic_name  \\\n",
       "0      943         0             3            m/0814255      Ben McEachen   \n",
       "1     7242         0             6            m/0814255      Nick Schager   \n",
       "2     1046         0             7            m/0814255  Bill Goodykoontz   \n",
       "3     4895         0             8            m/0814255    Jordan Hoffman   \n",
       "4     4517         0             9            m/0814255      Jim Schembri   \n",
       "\n",
       "   top_critic           publisher_name review_type  review_score review_date  \\\n",
       "0       False  Sunday Mail (Australia)       Fresh          0.70  2010-02-09   \n",
       "1       False           Slant Magazine      Rotten          0.25  2010-02-10   \n",
       "2        True         Arizona Republic       Fresh          0.70  2010-02-10   \n",
       "3       False                      UGO       Fresh          0.70  2010-02-10   \n",
       "4        True      The Age (Australia)       Fresh          0.60  2010-02-10   \n",
       "\n",
       "                                      review_content  \n",
       "0  Whether audiences will get behind The Lightnin...  \n",
       "1  Harry Potter knockoffs don't come more transpa...  \n",
       "2  Percy Jackson isn't a great movie, but it's a ...  \n",
       "3                         Fun, brisk and imaginative  \n",
       "4  Crammed with dragons, set-destroying fights an...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "709e094a-80b6-4342-a392-d691b4b399bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = merged_df[['user_id', 'movie_id', 'review_score', 'review_content', 'review_type','review_date', 'critic_name', 'top_critic', 'publisher_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "88911126-1819-4a5c-bea3-137055164c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_date</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Jordan Hoffman</td>\n",
       "      <td>False</td>\n",
       "      <td>UGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  review_score  \\\n",
       "0      943         0          0.70   \n",
       "1     7242         0          0.25   \n",
       "2     1046         0          0.70   \n",
       "3     4895         0          0.70   \n",
       "4     4517         0          0.60   \n",
       "\n",
       "                                      review_content review_type review_date  \\\n",
       "0  Whether audiences will get behind The Lightnin...       Fresh  2010-02-09   \n",
       "1  Harry Potter knockoffs don't come more transpa...      Rotten  2010-02-10   \n",
       "2  Percy Jackson isn't a great movie, but it's a ...       Fresh  2010-02-10   \n",
       "3                         Fun, brisk and imaginative       Fresh  2010-02-10   \n",
       "4  Crammed with dragons, set-destroying fights an...       Fresh  2010-02-10   \n",
       "\n",
       "        critic_name  top_critic           publisher_name  \n",
       "0      Ben McEachen       False  Sunday Mail (Australia)  \n",
       "1      Nick Schager       False           Slant Magazine  \n",
       "2  Bill Goodykoontz        True         Arizona Republic  \n",
       "3    Jordan Hoffman       False                      UGO  \n",
       "4      Jim Schembri        True      The Age (Australia)  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "806cd8f6-6260-408e-b5df-01aac19fc8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752664"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e48636d5-5f9a-438d-9da6-848d14818925",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  23,521.    Elapsed: 0:05:17.\n",
      "  Batch   200  of  23,521.    Elapsed: 0:05:48.\n",
      "  Batch   300  of  23,521.    Elapsed: 0:06:18.\n",
      "  Batch   400  of  23,521.    Elapsed: 0:06:49.\n",
      "  Batch   500  of  23,521.    Elapsed: 0:07:20.\n",
      "  Batch   600  of  23,521.    Elapsed: 0:07:51.\n",
      "  Batch   700  of  23,521.    Elapsed: 0:08:22.\n",
      "  Batch   800  of  23,521.    Elapsed: 0:08:54.\n",
      "  Batch   900  of  23,521.    Elapsed: 0:09:25.\n",
      "  Batch 1,000  of  23,521.    Elapsed: 0:09:56.\n",
      "  Batch 1,100  of  23,521.    Elapsed: 0:10:27.\n",
      "  Batch 1,200  of  23,521.    Elapsed: 0:10:58.\n",
      "  Batch 1,300  of  23,521.    Elapsed: 0:11:29.\n",
      "  Batch 1,400  of  23,521.    Elapsed: 0:12:00.\n",
      "  Batch 1,500  of  23,521.    Elapsed: 0:12:31.\n",
      "  Batch 1,600  of  23,521.    Elapsed: 0:13:02.\n",
      "  Batch 1,700  of  23,521.    Elapsed: 0:13:33.\n",
      "  Batch 1,800  of  23,521.    Elapsed: 0:14:05.\n",
      "  Batch 1,900  of  23,521.    Elapsed: 0:14:36.\n",
      "  Batch 2,000  of  23,521.    Elapsed: 0:15:07.\n",
      "  Batch 2,100  of  23,521.    Elapsed: 0:15:38.\n",
      "  Batch 2,200  of  23,521.    Elapsed: 0:16:09.\n",
      "  Batch 2,300  of  23,521.    Elapsed: 0:16:40.\n",
      "  Batch 2,400  of  23,521.    Elapsed: 0:17:11.\n",
      "  Batch 2,500  of  23,521.    Elapsed: 0:17:42.\n",
      "  Batch 2,600  of  23,521.    Elapsed: 0:18:13.\n",
      "  Batch 2,700  of  23,521.    Elapsed: 0:18:44.\n",
      "  Batch 2,800  of  23,521.    Elapsed: 0:19:16.\n",
      "  Batch 2,900  of  23,521.    Elapsed: 0:19:48.\n",
      "  Batch 3,000  of  23,521.    Elapsed: 0:20:19.\n",
      "  Batch 3,100  of  23,521.    Elapsed: 0:20:50.\n",
      "  Batch 3,200  of  23,521.    Elapsed: 0:21:21.\n",
      "  Batch 3,300  of  23,521.    Elapsed: 0:21:52.\n",
      "  Batch 3,400  of  23,521.    Elapsed: 0:22:23.\n",
      "  Batch 3,500  of  23,521.    Elapsed: 0:22:55.\n",
      "  Batch 3,600  of  23,521.    Elapsed: 0:23:26.\n",
      "  Batch 3,700  of  23,521.    Elapsed: 0:23:57.\n",
      "  Batch 3,800  of  23,521.    Elapsed: 0:24:28.\n",
      "  Batch 3,900  of  23,521.    Elapsed: 0:24:59.\n",
      "  Batch 4,000  of  23,521.    Elapsed: 0:25:30.\n",
      "  Batch 4,100  of  23,521.    Elapsed: 0:26:01.\n",
      "  Batch 4,200  of  23,521.    Elapsed: 0:26:32.\n",
      "  Batch 4,300  of  23,521.    Elapsed: 0:27:03.\n",
      "  Batch 4,400  of  23,521.    Elapsed: 0:27:34.\n",
      "  Batch 4,500  of  23,521.    Elapsed: 0:28:06.\n",
      "  Batch 4,600  of  23,521.    Elapsed: 0:28:38.\n",
      "  Batch 4,700  of  23,521.    Elapsed: 0:29:09.\n",
      "  Batch 4,800  of  23,521.    Elapsed: 0:29:40.\n",
      "  Batch 4,900  of  23,521.    Elapsed: 0:30:11.\n",
      "  Batch 5,000  of  23,521.    Elapsed: 0:30:42.\n",
      "  Batch 5,100  of  23,521.    Elapsed: 0:31:13.\n",
      "  Batch 5,200  of  23,521.    Elapsed: 0:31:44.\n",
      "  Batch 5,300  of  23,521.    Elapsed: 0:32:15.\n",
      "  Batch 5,400  of  23,521.    Elapsed: 0:32:46.\n",
      "  Batch 5,500  of  23,521.    Elapsed: 0:33:18.\n",
      "  Batch 5,600  of  23,521.    Elapsed: 0:33:49.\n",
      "  Batch 5,700  of  23,521.    Elapsed: 0:34:20.\n",
      "  Batch 5,800  of  23,521.    Elapsed: 0:34:51.\n",
      "  Batch 5,900  of  23,521.    Elapsed: 0:35:22.\n",
      "  Batch 6,000  of  23,521.    Elapsed: 0:35:53.\n",
      "  Batch 6,100  of  23,521.    Elapsed: 0:36:24.\n",
      "  Batch 6,200  of  23,521.    Elapsed: 0:36:55.\n",
      "  Batch 6,300  of  23,521.    Elapsed: 0:37:26.\n",
      "  Batch 6,400  of  23,521.    Elapsed: 0:37:57.\n",
      "  Batch 6,500  of  23,521.    Elapsed: 0:38:28.\n",
      "  Batch 6,600  of  23,521.    Elapsed: 0:38:59.\n",
      "  Batch 6,700  of  23,521.    Elapsed: 0:39:30.\n",
      "  Batch 6,800  of  23,521.    Elapsed: 0:40:01.\n",
      "  Batch 6,900  of  23,521.    Elapsed: 0:40:32.\n",
      "  Batch 7,000  of  23,521.    Elapsed: 0:41:03.\n",
      "  Batch 7,100  of  23,521.    Elapsed: 0:41:35.\n",
      "  Batch 7,200  of  23,521.    Elapsed: 0:42:06.\n",
      "  Batch 7,300  of  23,521.    Elapsed: 0:42:37.\n",
      "  Batch 7,400  of  23,521.    Elapsed: 0:43:08.\n",
      "  Batch 7,500  of  23,521.    Elapsed: 0:43:39.\n",
      "  Batch 7,600  of  23,521.    Elapsed: 0:44:10.\n",
      "  Batch 7,700  of  23,521.    Elapsed: 0:44:41.\n",
      "  Batch 7,800  of  23,521.    Elapsed: 0:45:12.\n",
      "  Batch 7,900  of  23,521.    Elapsed: 0:45:43.\n",
      "  Batch 8,000  of  23,521.    Elapsed: 0:46:14.\n",
      "  Batch 8,100  of  23,521.    Elapsed: 0:46:45.\n",
      "  Batch 8,200  of  23,521.    Elapsed: 0:47:16.\n",
      "  Batch 8,300  of  23,521.    Elapsed: 0:47:47.\n",
      "  Batch 8,400  of  23,521.    Elapsed: 0:48:18.\n",
      "  Batch 8,500  of  23,521.    Elapsed: 0:48:49.\n",
      "  Batch 8,600  of  23,521.    Elapsed: 0:49:20.\n",
      "  Batch 8,700  of  23,521.    Elapsed: 0:49:51.\n",
      "  Batch 8,800  of  23,521.    Elapsed: 0:50:23.\n",
      "  Batch 8,900  of  23,521.    Elapsed: 0:50:54.\n",
      "  Batch 9,000  of  23,521.    Elapsed: 0:51:25.\n",
      "  Batch 9,100  of  23,521.    Elapsed: 0:51:56.\n",
      "  Batch 9,200  of  23,521.    Elapsed: 0:52:27.\n",
      "  Batch 9,300  of  23,521.    Elapsed: 0:52:58.\n",
      "  Batch 9,400  of  23,521.    Elapsed: 0:53:29.\n",
      "  Batch 9,500  of  23,521.    Elapsed: 0:54:00.\n",
      "  Batch 9,600  of  23,521.    Elapsed: 0:54:31.\n",
      "  Batch 9,700  of  23,521.    Elapsed: 0:55:02.\n",
      "  Batch 9,800  of  23,521.    Elapsed: 0:55:33.\n",
      "  Batch 9,900  of  23,521.    Elapsed: 0:56:04.\n",
      "  Batch 10,000  of  23,521.    Elapsed: 0:56:35.\n",
      "  Batch 10,100  of  23,521.    Elapsed: 0:57:06.\n",
      "  Batch 10,200  of  23,521.    Elapsed: 0:57:37.\n",
      "  Batch 10,300  of  23,521.    Elapsed: 0:58:08.\n",
      "  Batch 10,400  of  23,521.    Elapsed: 0:58:39.\n",
      "  Batch 10,500  of  23,521.    Elapsed: 0:59:10.\n",
      "  Batch 10,600  of  23,521.    Elapsed: 0:59:41.\n",
      "  Batch 10,700  of  23,521.    Elapsed: 1:00:13.\n",
      "  Batch 10,800  of  23,521.    Elapsed: 1:00:44.\n",
      "  Batch 10,900  of  23,521.    Elapsed: 1:01:15.\n",
      "  Batch 11,000  of  23,521.    Elapsed: 1:01:46.\n",
      "  Batch 11,100  of  23,521.    Elapsed: 1:02:17.\n",
      "  Batch 11,200  of  23,521.    Elapsed: 1:02:48.\n",
      "  Batch 11,300  of  23,521.    Elapsed: 1:03:19.\n",
      "  Batch 11,400  of  23,521.    Elapsed: 1:03:50.\n",
      "  Batch 11,500  of  23,521.    Elapsed: 1:04:21.\n",
      "  Batch 11,600  of  23,521.    Elapsed: 1:04:52.\n",
      "  Batch 11,700  of  23,521.    Elapsed: 1:05:23.\n",
      "  Batch 11,800  of  23,521.    Elapsed: 1:05:54.\n",
      "  Batch 11,900  of  23,521.    Elapsed: 1:06:25.\n",
      "  Batch 12,000  of  23,521.    Elapsed: 1:06:56.\n",
      "  Batch 12,100  of  23,521.    Elapsed: 1:07:27.\n",
      "  Batch 12,200  of  23,521.    Elapsed: 1:07:58.\n",
      "  Batch 12,300  of  23,521.    Elapsed: 1:08:30.\n",
      "  Batch 12,400  of  23,521.    Elapsed: 1:09:01.\n",
      "  Batch 12,500  of  23,521.    Elapsed: 1:09:32.\n",
      "  Batch 12,600  of  23,521.    Elapsed: 1:10:03.\n",
      "  Batch 12,700  of  23,521.    Elapsed: 1:10:34.\n",
      "  Batch 12,800  of  23,521.    Elapsed: 1:11:05.\n",
      "  Batch 12,900  of  23,521.    Elapsed: 1:11:36.\n",
      "  Batch 13,000  of  23,521.    Elapsed: 1:12:07.\n",
      "  Batch 13,100  of  23,521.    Elapsed: 1:12:38.\n",
      "  Batch 13,200  of  23,521.    Elapsed: 1:13:09.\n",
      "  Batch 13,300  of  23,521.    Elapsed: 1:13:40.\n",
      "  Batch 13,400  of  23,521.    Elapsed: 1:14:11.\n",
      "  Batch 13,500  of  23,521.    Elapsed: 1:14:42.\n",
      "  Batch 13,600  of  23,521.    Elapsed: 1:15:13.\n",
      "  Batch 13,700  of  23,521.    Elapsed: 1:15:44.\n",
      "  Batch 13,800  of  23,521.    Elapsed: 1:16:16.\n",
      "  Batch 13,900  of  23,521.    Elapsed: 1:16:47.\n",
      "  Batch 14,000  of  23,521.    Elapsed: 1:17:18.\n",
      "  Batch 14,100  of  23,521.    Elapsed: 1:17:49.\n",
      "  Batch 14,200  of  23,521.    Elapsed: 1:18:20.\n",
      "  Batch 14,300  of  23,521.    Elapsed: 1:18:51.\n",
      "  Batch 14,400  of  23,521.    Elapsed: 1:19:22.\n",
      "  Batch 14,500  of  23,521.    Elapsed: 1:19:53.\n",
      "  Batch 14,600  of  23,521.    Elapsed: 1:20:24.\n",
      "  Batch 14,700  of  23,521.    Elapsed: 1:20:55.\n",
      "  Batch 14,800  of  23,521.    Elapsed: 1:21:26.\n",
      "  Batch 14,900  of  23,521.    Elapsed: 1:21:57.\n",
      "  Batch 15,000  of  23,521.    Elapsed: 1:22:28.\n",
      "  Batch 15,100  of  23,521.    Elapsed: 1:22:59.\n",
      "  Batch 15,200  of  23,521.    Elapsed: 1:23:31.\n",
      "  Batch 15,300  of  23,521.    Elapsed: 1:24:02.\n",
      "  Batch 15,400  of  23,521.    Elapsed: 1:24:33.\n",
      "  Batch 15,500  of  23,521.    Elapsed: 1:25:04.\n",
      "  Batch 15,600  of  23,521.    Elapsed: 1:25:35.\n",
      "  Batch 15,700  of  23,521.    Elapsed: 1:26:06.\n",
      "  Batch 15,800  of  23,521.    Elapsed: 1:26:37.\n",
      "  Batch 15,900  of  23,521.    Elapsed: 1:27:08.\n",
      "  Batch 16,000  of  23,521.    Elapsed: 1:27:39.\n",
      "  Batch 16,100  of  23,521.    Elapsed: 1:28:10.\n",
      "  Batch 16,200  of  23,521.    Elapsed: 1:28:41.\n",
      "  Batch 16,300  of  23,521.    Elapsed: 1:29:12.\n",
      "  Batch 16,400  of  23,521.    Elapsed: 1:29:44.\n",
      "  Batch 16,500  of  23,521.    Elapsed: 1:30:15.\n",
      "  Batch 16,600  of  23,521.    Elapsed: 1:30:46.\n",
      "  Batch 16,700  of  23,521.    Elapsed: 1:31:17.\n",
      "  Batch 16,800  of  23,521.    Elapsed: 1:31:48.\n",
      "  Batch 16,900  of  23,521.    Elapsed: 1:32:19.\n",
      "  Batch 17,000  of  23,521.    Elapsed: 1:32:50.\n",
      "  Batch 17,100  of  23,521.    Elapsed: 1:33:21.\n",
      "  Batch 17,200  of  23,521.    Elapsed: 1:33:52.\n",
      "  Batch 17,300  of  23,521.    Elapsed: 1:34:23.\n",
      "  Batch 17,400  of  23,521.    Elapsed: 1:34:54.\n",
      "  Batch 17,500  of  23,521.    Elapsed: 1:35:25.\n",
      "  Batch 17,600  of  23,521.    Elapsed: 1:35:56.\n",
      "  Batch 17,700  of  23,521.    Elapsed: 1:36:28.\n",
      "  Batch 17,800  of  23,521.    Elapsed: 1:36:59.\n",
      "  Batch 17,900  of  23,521.    Elapsed: 1:37:30.\n",
      "  Batch 18,000  of  23,521.    Elapsed: 1:38:01.\n",
      "  Batch 18,100  of  23,521.    Elapsed: 1:38:32.\n",
      "  Batch 18,200  of  23,521.    Elapsed: 1:39:03.\n",
      "  Batch 18,300  of  23,521.    Elapsed: 1:39:34.\n",
      "  Batch 18,400  of  23,521.    Elapsed: 1:40:05.\n",
      "  Batch 18,500  of  23,521.    Elapsed: 1:40:36.\n",
      "  Batch 18,600  of  23,521.    Elapsed: 1:41:07.\n",
      "  Batch 18,700  of  23,521.    Elapsed: 1:41:38.\n",
      "  Batch 18,800  of  23,521.    Elapsed: 1:42:09.\n",
      "  Batch 18,900  of  23,521.    Elapsed: 1:42:40.\n",
      "  Batch 19,000  of  23,521.    Elapsed: 1:43:11.\n",
      "  Batch 19,100  of  23,521.    Elapsed: 1:43:42.\n",
      "  Batch 19,200  of  23,521.    Elapsed: 1:44:13.\n",
      "  Batch 19,300  of  23,521.    Elapsed: 1:44:44.\n",
      "  Batch 19,400  of  23,521.    Elapsed: 1:45:15.\n",
      "  Batch 19,500  of  23,521.    Elapsed: 1:45:47.\n",
      "  Batch 19,600  of  23,521.    Elapsed: 1:46:18.\n",
      "  Batch 19,700  of  23,521.    Elapsed: 1:46:49.\n",
      "  Batch 19,800  of  23,521.    Elapsed: 1:47:20.\n",
      "  Batch 19,900  of  23,521.    Elapsed: 1:47:51.\n",
      "  Batch 20,000  of  23,521.    Elapsed: 1:48:22.\n",
      "  Batch 20,100  of  23,521.    Elapsed: 1:48:53.\n",
      "  Batch 20,200  of  23,521.    Elapsed: 1:49:24.\n",
      "  Batch 20,300  of  23,521.    Elapsed: 1:49:55.\n",
      "  Batch 20,400  of  23,521.    Elapsed: 1:50:26.\n",
      "  Batch 20,500  of  23,521.    Elapsed: 1:50:57.\n",
      "  Batch 20,600  of  23,521.    Elapsed: 1:51:28.\n",
      "  Batch 20,700  of  23,521.    Elapsed: 1:51:59.\n",
      "  Batch 20,800  of  23,521.    Elapsed: 1:52:30.\n",
      "  Batch 20,900  of  23,521.    Elapsed: 1:53:01.\n",
      "  Batch 21,000  of  23,521.    Elapsed: 1:53:32.\n",
      "  Batch 21,100  of  23,521.    Elapsed: 1:54:03.\n",
      "  Batch 21,200  of  23,521.    Elapsed: 1:54:34.\n",
      "  Batch 21,300  of  23,521.    Elapsed: 1:55:05.\n",
      "  Batch 21,400  of  23,521.    Elapsed: 1:55:37.\n",
      "  Batch 21,500  of  23,521.    Elapsed: 1:56:08.\n",
      "  Batch 21,600  of  23,521.    Elapsed: 1:56:39.\n",
      "  Batch 21,700  of  23,521.    Elapsed: 1:57:10.\n",
      "  Batch 21,800  of  23,521.    Elapsed: 1:57:41.\n",
      "  Batch 21,900  of  23,521.    Elapsed: 1:58:12.\n",
      "  Batch 22,000  of  23,521.    Elapsed: 1:58:43.\n",
      "  Batch 22,100  of  23,521.    Elapsed: 1:59:14.\n",
      "  Batch 22,200  of  23,521.    Elapsed: 1:59:45.\n",
      "  Batch 22,300  of  23,521.    Elapsed: 2:00:16.\n",
      "  Batch 22,400  of  23,521.    Elapsed: 2:00:47.\n",
      "  Batch 22,500  of  23,521.    Elapsed: 2:01:18.\n",
      "  Batch 22,600  of  23,521.    Elapsed: 2:01:49.\n",
      "  Batch 22,700  of  23,521.    Elapsed: 2:02:20.\n",
      "  Batch 22,800  of  23,521.    Elapsed: 2:02:51.\n",
      "  Batch 22,900  of  23,521.    Elapsed: 2:03:22.\n",
      "  Batch 23,000  of  23,521.    Elapsed: 2:03:53.\n",
      "  Batch 23,100  of  23,521.    Elapsed: 2:04:24.\n",
      "  Batch 23,200  of  23,521.    Elapsed: 2:04:56.\n",
      "  Batch 23,300  of  23,521.    Elapsed: 2:05:27.\n",
      "  Batch 23,400  of  23,521.    Elapsed: 2:05:58.\n",
      "  Batch 23,500  of  23,521.    Elapsed: 2:06:29.\n",
      "  Labeling took: 2:06:35\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "labels = test_sentence_many(model, device, tokenizer, rating_df.review_content)\n",
    "print(\"  Labeling took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "02e373ef-def5-42f8-b803-e1b6a48a458f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752664"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ee9d43e3-1fe8-4b04-a471-c19eb61172c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch37\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "rating_df['sentiment'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b8d1afe0-9ab3-46e4-970b-d77d4f86d7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_date</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Jordan Hoffman</td>\n",
       "      <td>False</td>\n",
       "      <td>UGO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  review_score  \\\n",
       "0      943         0          0.70   \n",
       "1     7242         0          0.25   \n",
       "2     1046         0          0.70   \n",
       "3     4895         0          0.70   \n",
       "4     4517         0          0.60   \n",
       "\n",
       "                                      review_content review_type review_date  \\\n",
       "0  Whether audiences will get behind The Lightnin...       Fresh  2010-02-09   \n",
       "1  Harry Potter knockoffs don't come more transpa...      Rotten  2010-02-10   \n",
       "2  Percy Jackson isn't a great movie, but it's a ...       Fresh  2010-02-10   \n",
       "3                         Fun, brisk and imaginative       Fresh  2010-02-10   \n",
       "4  Crammed with dragons, set-destroying fights an...       Fresh  2010-02-10   \n",
       "\n",
       "        critic_name  top_critic           publisher_name  sentiment  \n",
       "0      Ben McEachen       False  Sunday Mail (Australia)          2  \n",
       "1      Nick Schager       False           Slant Magazine          0  \n",
       "2  Bill Goodykoontz        True         Arizona Republic          3  \n",
       "3    Jordan Hoffman       False                      UGO          4  \n",
       "4      Jim Schembri        True      The Age (Australia)          1  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "51a54291-3dc7-4b08-bab3-409bebf6b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../../data/rotten_tomato/sentiment_analysis_data/'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1a54e107-bce8-4cfd-9238-b7b0977a8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv('./../../data/rotten_tomato/rotten_rating_review_sentiment_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ff22f-871b-4b3b-bd31-82cb2cdae624",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. Pretraining 층으로만 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585187e-a749-4790-884f-11ba6e86a529",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_no_finetuning = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "# model_no_finetuning.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8a0a2-c26d-4580-8cac-f6d221d9fe4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #시작 시간 설정\n",
    "# start_time = time.time()\n",
    "\n",
    "# # 평가모드로 변경\n",
    "# model_rotten2.eval()\n",
    "\n",
    "# # 변수 초기화\n",
    "# eval_loss, eval_accuracy = 0, 0\n",
    "# nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "# for step, batch in enumerate(test_dataloader):\n",
    "#     # 경과 정보 표시\n",
    "#     if step % 100 == 0 and not step == 0:\n",
    "#         elapsed = format_time(time.time() - start_time)\n",
    "#         print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "#     # 배치를 GPU에 넣음\n",
    "#     batch = tuple(b.to(device) for b in batch)\n",
    "    \n",
    "#     # 배치에서 데이터 추출\n",
    "#     b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "#     # 그래디언트 계산 안함\n",
    "#     with torch.no_grad():     \n",
    "#         # Forward 수행\n",
    "#         outputs = model_rotten2(b_input_ids, \n",
    "#                         token_type_ids=None, \n",
    "#                         attention_mask=b_input_mask)\n",
    "    \n",
    "#     # 로스 구함\n",
    "#     logits = outputs[0]\n",
    "\n",
    "#     # CPU로 데이터 이동\n",
    "#     logits = logits.detach().cpu().numpy()\n",
    "#     label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "#     # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "#     eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"Accuracy: {0:.2f}\".format(eval_accuracy/len(test_dataloader)))\n",
    "# print(\"Test took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb764a0-bbb7-4fc5-9ace-8326b9084a33",
   "metadata": {},
   "source": [
    "---\n",
    "### 8. 특정 영화에 대한 긍정/부정 리뷰 취합 후 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8fa982f-5a4c-47a3-a968-92539d328654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'rotten_review_scaled_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0efece-aaf1-4a64-9a28-ad8bd8290cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jordan Hoffman</td>\n",
       "      <td>False</td>\n",
       "      <td>UGO</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link       critic_name  top_critic           publisher_name  \\\n",
       "0            m/0814255      Ben McEachen       False  Sunday Mail (Australia)   \n",
       "1            m/0814255      Nick Schager       False           Slant Magazine   \n",
       "2            m/0814255  Bill Goodykoontz        True         Arizona Republic   \n",
       "3            m/0814255    Jordan Hoffman       False                      UGO   \n",
       "4            m/0814255        Mark Adams       False        Daily Mirror (UK)   \n",
       "\n",
       "  review_type  review_score review_date  \\\n",
       "0       Fresh          1.00  2010-02-09   \n",
       "1      Rotten          0.25  2010-02-10   \n",
       "2       Fresh          1.00  2010-02-10   \n",
       "3       Fresh          0.70  2010-02-10   \n",
       "4       Fresh          0.80  2010-02-10   \n",
       "\n",
       "                                      review_content  label  \n",
       "0  Whether audiences will get behind The Lightnin...      1  \n",
       "1  Harry Potter knockoffs don't come more transpa...      0  \n",
       "2  Percy Jackson isn't a great movie, but it's a ...      1  \n",
       "3                         Fun, brisk and imaginative      1  \n",
       "4  This action-packed fantasy adventure, based on...      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4732b5f-24c7-479b-ad60-d5f7451bb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df[['rotten_tomatoes_link','review_content', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8616a9cf-0bad-42f9-9d4f-1ef06a45da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>review_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link                                     review_content  \\\n",
       "0            m/0814255  Whether audiences will get behind The Lightnin...   \n",
       "1            m/0814255  Harry Potter knockoffs don't come more transpa...   \n",
       "2            m/0814255  Percy Jackson isn't a great movie, but it's a ...   \n",
       "3            m/0814255                         Fun, brisk and imaginative   \n",
       "4            m/0814255  This action-packed fantasy adventure, based on...   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "73d5b07d-0fad-4417-bcb5-dd42a17ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_review = df_review.pivot_table(index='rotten_tomatoes_link', columns='label', aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c362eef3-ca3d-42e1-ae60-6487366e2a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m/+_one_2019</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/+h</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/-_man</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/-cule_valley_of_the_lost_ants</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/0814255</th>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zoom_2006</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zootopia</th>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zorba_the_greek</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zulu</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zulu_dawn</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16933 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                review_content     \n",
       "label                                        0    1\n",
       "rotten_tomatoes_link                               \n",
       "m/+_one_2019                                 0   33\n",
       "m/+h                                         2    2\n",
       "m/-_man                                      1    3\n",
       "m/-cule_valley_of_the_lost_ants              0    5\n",
       "m/0814255                                   12   34\n",
       "...                                        ...  ...\n",
       "m/zoom_2006                                 22    3\n",
       "m/zootopia                                   2  166\n",
       "m/zorba_the_greek                            0    3\n",
       "m/zulu                                       0    4\n",
       "m/zulu_dawn                                  0    3\n",
       "\n",
       "[16933 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8d1a985e-9f24-4102-8806-64213ae930c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                label\n",
       "review_content  0        12\n",
       "                1        34\n",
       "Name: m/0814255, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review.loc['m/0814255']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "db134566-29a3-4856-89db-ba490ba0bb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                label\n",
       "review_content  0        48\n",
       "                1        12\n",
       "Name: m/10000_bc, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review.loc['m/10000_bc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75839b-ae10-4c73-b238-96ebe59d3b8e",
   "metadata": {},
   "source": [
    "- Movie1: 'm/0814255'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87a5547a-85dd-4f14-a25a-29e9675f60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정, 부정 리뷰들을 취합 후 파일저장\n",
    "def movie_sentiment_filter(df, movie_link, file_name):\n",
    "    condition = df['rotten_tomatoes_link'] == movie_link\n",
    "    df = df[condition]\n",
    "    \n",
    "    pos_review_list = df[df['label'] == 1].reset_index(drop=True).review_content\n",
    "    movie1_pos = \" \".join(pos_review_list)\n",
    "    \n",
    "    neg_review_list = df[df['label'] == 0].reset_index(drop=True).review_content\n",
    "    movie1_neg = \" \".join(neg_review_list)\n",
    "    \n",
    "    f = open(path + f\"{file_name}_pos.txt\", 'w')\n",
    "    f.write(movie1_pos)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(path + f\"{file_name}_neg.txt\", 'w')\n",
    "    f.write(movie1_neg)\n",
    "    f.close()\n",
    "    \n",
    "    print(f\"{file_name}_pos/neg save finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3b07188-91f8-489e-ac06-d0a4003ef8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie1_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/0814255', file_name='movie1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e825ec1e-ad86-4639-8bcb-093b3f797eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie2_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/0878835', file_name='movie2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d912b320-11fc-4aac-b174-8aba8a4cfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie3_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/10000_bc', file_name='movie3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b536f-2777-46eb-a04b-23204028994d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
