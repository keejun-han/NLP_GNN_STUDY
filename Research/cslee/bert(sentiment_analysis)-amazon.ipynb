{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc90e175-acc6-4ec8-b6b8-09d85a721c13",
   "metadata": {},
   "source": [
    "# Amazon BERT - Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c770538e-13b1-4954-ba23-822b574380b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from utils import (\n",
    "    tokenizer_setting,\n",
    "    preprocessing,\n",
    "    GPU_setting,\n",
    "    hyperparmeter_setting,\n",
    "    flat_accuracy,\n",
    "    format_time,\n",
    "    initial_setting,\n",
    "    run_train,\n",
    "    run_test,\n",
    "    convert_input_data,\n",
    "    test_sentence_unit,\n",
    "    test_sentence_many\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f02b1-10d6-4b02-ae3d-b6442005cbc3",
   "metadata": {},
   "source": [
    "### 1. Initial Setting\n",
    "- Load the data\n",
    "- Split train, test data\n",
    "- Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9c73c3-f594-4455-8e55-ae8fa90514c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions.csv', 'test.tsv', 'test.tsv.zip', 'train.tsv', 'train.tsv.zip']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './../../data/amazon/sentiment_analysis_data/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db002eaf-ab84-4612-a514-90b6823486ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path + 'train.tsv', sep=\"\\t\")\n",
    "test_df = pd.read_csv(path + 'test.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ff6b97-f19b-4004-88c7-8b2b05d6a779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55de2a5-3389-4c8b-9c94-cfa96117722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf79055-824e-4d2f-8fe4-7b68cedf1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['Phrase']\n",
    "y_train = train_df['Sentiment']\n",
    "\n",
    "X_test  = test_df['Phrase']\n",
    "y_test = pd.read_csv(path + 'predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59691c48-a372-4263-b2a6-62cb397c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(feature_df, \n",
    "#                                                     target_df, \n",
    "#                                                     test_size=0.3, \n",
    "#                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c93d42e-6847-4c7f-9c0d-aab2fe2a5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2d1ab-edf5-4008-bbaf-72696b64909b",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e4654dd-7eda-4ef7-bd37-e776ce1b0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader, validation_dataloader = preprocessing(X_train.review_content, y_train, tokenizer, process_type='train')\n",
    "train_dataloader, validation_dataloader = preprocessing(X_train, y_train, tokenizer, process_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "634e3b3c-c9d7-4a25-96d6-af4ca5d3b41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = preprocessing(X_test.review_content, y_test, tokenizer, process_type='test')\n",
    "test_dataloader = preprocessing(X_test, y_test, tokenizer, process_type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02560d9-c9e8-435f-9dcd-e4fe99a0ac08",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6564be32-43de-4b24-b6f1-23d49bb9e563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading took: 0:00:06\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels = 5) #label개수에 따라 변경\n",
    "model.cuda()\n",
    "print(\"  Loading took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56441de3-2d8c-4d91-b7c5-89f51084049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device 0 : NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "device = GPU_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af1907ef-3070-45fa-97e6-3a21832b55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, epochs, total_steps, scheduler = hyperparmeter_setting(model, train_dataloader, lr=2e-5, eps=1e-8, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "934fb112-0be2-4ca4-9335-65dc4c451bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initial_setting(model, seed_val=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c759a-4f05-46da-97aa-524a52eed31f",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8847067f-60f6-4a89-8e94-15c464d4c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, path, file_name='checkpoint.pth.tar'):\n",
    "    file_path = path + file_name\n",
    "    print(f\"file_path: {file_path}\")\n",
    "    torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98e7f1-8bcb-47bf-8daf-6bc5f0087dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, epochs, train_dataloader, validation_dataloader, optimizer, scheduler, device, path):\n",
    "    first_start_time = time.time()\n",
    "    \n",
    "    # 에폭 수만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               1. Training\n",
    "        # ========================================\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 로스 초기화\n",
    "        total_loss = 0\n",
    "\n",
    "        # 훈련모드로 변경\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # 경과 정보 표시 (step 500번마다 출력)\n",
    "            if step % 500 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - start_time)\n",
    "                print('Batch {:>5,}  of  {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # 배치를 GPU에 올림\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            # 배치에서 데이터 추출 (input, mask, label 순으로 넣었었음)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_input_mask,\n",
    "                           token_type_ids=None,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            # 로스 구함\n",
    "            loss = outputs.loss # outputs[0]\n",
    "\n",
    "            # 총 로스 계산\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward 수행으로 그래디언트 계산 (Back-propagation)\n",
    "            loss.backward()\n",
    "\n",
    "            # 그래디언트 클리핑\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0) # 예제 코드에서는 1.0이었음\n",
    "\n",
    "            # 그래디언트를 이용해 가중치 파라미터를 lr만큼 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "            # 스케줄러로 학습률 감소\n",
    "            scheduler.step()\n",
    "\n",
    "            # 그래디언트 초기화\n",
    "            ## (호출시 경사값을 0으로 설정. 이유 : 반복 때마다 기울기를 새로 계산하기 때문)\n",
    "            model.zero_grad()\n",
    "\n",
    "        # 1 에폭이 끝나면 평균 train 로스 계산 (전체 loss / 배치 수)\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - start_time)))\n",
    "        \n",
    "        # 체크포인트 저장\n",
    "        print(\"  Model Checkpoint Save\")\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict()\n",
    "            }, path)\n",
    "        \n",
    "        # ========================================\n",
    "        #               2. Validation\n",
    "        # ========================================\n",
    "\n",
    "        # 1 에폭이 끝나면 validation 시행\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 평가 모드로 변경\n",
    "        model.eval()\n",
    "\n",
    "        # 변수 초기화\n",
    "        total_valid_accuracy = 0\n",
    "        nb_valid_steps = 0\n",
    "\n",
    "        # valid 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # 그래디언트 계산 안함!\n",
    "            with torch.no_grad():\n",
    "                # Forward 수행\n",
    "                outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask)\n",
    "\n",
    "            # 로스 구함 (train할 때는 loss, validation할 때는 logits)\n",
    "            ## logits은 softmax를 거치기 전의 classification score를 반환합니다. shape: (batch_size, config.num_labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # CPU로 데이터 이동\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "            valid_accuracy = flat_accuracy(logits, label_ids)\n",
    "            total_valid_accuracy += valid_accuracy\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(total_valid_accuracy/len(validation_dataloader)))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - start_time)))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Total took: {:}\".format(format_time(time.time() - first_start_time)))\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c355ec4a-dc64-4159-b08e-f992f42b9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d944acc-8a08-4989-8093-c9e086ecfb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "Batch   500  of  4,390. Elapsed: 0:07:58.\n",
      "Batch 1,000  of  4,390. Elapsed: 0:15:56.\n",
      "Batch 1,500  of  4,390. Elapsed: 0:23:55.\n",
      "Batch 2,000  of  4,390. Elapsed: 0:31:53.\n",
      "Batch 2,500  of  4,390. Elapsed: 0:39:52.\n",
      "Batch 3,000  of  4,390. Elapsed: 0:47:51.\n",
      "Batch 3,500  of  4,390. Elapsed: 0:55:51.\n",
      "Batch 4,000  of  4,390. Elapsed: 1:03:50.\n",
      "\n",
      "  Average training loss: 0.62\n",
      "  Training epoch took: 1:10:04\n",
      "  Model Checkpoint Save\n",
      "file_path: ./../../data/rotten_tomato/sentiment_analysis_data/checkpoint.pth.tar\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation took: 0:02:31\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "Batch   500  of  4,390. Elapsed: 0:07:59.\n",
      "Batch 1,000  of  4,390. Elapsed: 0:15:57.\n",
      "Batch 1,500  of  4,390. Elapsed: 0:23:59.\n",
      "Batch 2,000  of  4,390. Elapsed: 0:31:59.\n",
      "Batch 2,500  of  4,390. Elapsed: 0:39:57.\n",
      "Batch 3,000  of  4,390. Elapsed: 0:47:55.\n",
      "Batch 3,500  of  4,390. Elapsed: 0:55:54.\n",
      "Batch 4,000  of  4,390. Elapsed: 1:03:52.\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epoch took: 1:10:05\n",
      "  Model Checkpoint Save\n",
      "file_path: ./../../data/rotten_tomato/sentiment_analysis_data/checkpoint.pth.tar\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation took: 0:02:31\n",
      "\n",
      "Total took: 2:25:19\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model = run_train(model, epochs, train_dataloader, validation_dataloader, optimizer, scheduler, device, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770509dc-eb47-47d1-9e53-299b609ecc3a",
   "metadata": {},
   "source": [
    "### 5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32564ce8-42f9-4a84-8d87-d2e664880b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"./../../data/rotten_tomato/sentiment_analysis_data/model_new.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b77020-5bf3-443c-a377-5768943d46dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./../../data/rotten_tomato/sentiment_analysis_data/model_new.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a88ef561-c4f7-4783-98c8-bd13a84a9b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./../../data/amazon/sentiment_analysis_data//model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./../../data/amazon/sentiment_analysis_data//model_save/tokenizer_config.json',\n",
       " './../../data/amazon/sentiment_analysis_data//model_save/special_tokens_map.json',\n",
       " './../../data/amazon/sentiment_analysis_data//model_save/vocab.txt',\n",
       " './../../data/amazon/sentiment_analysis_data//model_save/added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = path + '/model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc65a0-0b7f-4a84-8595-852be17a5177",
   "metadata": {},
   "source": [
    "- Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d1ba6fd-2ba8-4790-8ac4-6caf560fd947",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model_new = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model_new.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a418ae3-e60c-4c7f-87d7-a0b65a585db0",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4239e0d0-cfd3-481c-b91f-ffa97fbabf63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  2,072.    Elapsed: 0:00:31.\n",
      "  Batch   200  of  2,072.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  2,072.    Elapsed: 0:01:33.\n",
      "  Batch   400  of  2,072.    Elapsed: 0:02:04.\n",
      "  Batch   500  of  2,072.    Elapsed: 0:02:35.\n",
      "  Batch   600  of  2,072.    Elapsed: 0:03:07.\n",
      "  Batch   700  of  2,072.    Elapsed: 0:03:38.\n",
      "  Batch   800  of  2,072.    Elapsed: 0:04:09.\n",
      "  Batch   900  of  2,072.    Elapsed: 0:04:40.\n",
      "  Batch 1,000  of  2,072.    Elapsed: 0:05:11.\n",
      "  Batch 1,100  of  2,072.    Elapsed: 0:05:42.\n",
      "  Batch 1,200  of  2,072.    Elapsed: 0:06:13.\n",
      "  Batch 1,300  of  2,072.    Elapsed: 0:06:44.\n",
      "  Batch 1,400  of  2,072.    Elapsed: 0:07:15.\n",
      "  Batch 1,500  of  2,072.    Elapsed: 0:07:47.\n",
      "  Batch 1,600  of  2,072.    Elapsed: 0:08:18.\n",
      "  Batch 1,700  of  2,072.    Elapsed: 0:08:49.\n",
      "  Batch 1,800  of  2,072.    Elapsed: 0:09:20.\n",
      "  Batch 1,900  of  2,072.    Elapsed: 0:09:51.\n",
      "  Batch 2,000  of  2,072.    Elapsed: 0:10:22.\n",
      "\n",
      "Accuracy: 0.00\n",
      "Test took: 0:10:44\n"
     ]
    }
   ],
   "source": [
    "run_test(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4e5e-56db-46b0-91d4-7ba225fa5e52",
   "metadata": {},
   "source": [
    "- 단일 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a972496-a8bd-41c9-b9a1-56280b157ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.6424768  -3.59159    -0.14507934  3.7208323   3.9107153 ]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's a  great\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "539a5aba-dde1-46a1-bdff-608a9f2c582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2826602   0.88587826  1.9615097   0.792078   -2.2370389 ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Whether audiences will get behind The Lightning Thief is hard to predict. Overall, it's an entertaining introduction to a promising new world -- but will the consuming shadow of Potter be too big to break free of?\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81f76044-7c2c-4d96-bd71-1cb8d03f4968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6444795   1.9478985   2.4090805  -0.02791836 -3.761274  ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"First section is good, but last is bad.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af73efe5-f76a-4255-b380-e92c7f5b2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.9226365  0.8520015  3.7444754  0.5416726 -3.7775207]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's so so.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab1034e0-a010-49a0-8eb6-489e84f6423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.080648   1.6646496 -0.7384983 -2.6886609 -1.8533113]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is terrible.\"\n",
    "logits = test_sentence_unit(model, device, tokenizer, [sentence])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6959ae6-e6b9-4487-9e1e-60221f7c44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence_unit(model, device, tokenizer, sentence):\n",
    "        \n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(tokenizer, sentence)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783c3a2-7774-46fb-97f9-73b888992d44",
   "metadata": {},
   "source": [
    "- 여러 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bf93931-a9b8-41d8-b6c0-3fd1cd43143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../../data/amazon/sentiment_analysis_data/'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bec74c6-55b2-4e3e-9f57-2af65950875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = './../../data/amazon/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6aaa68f7-e1e4-48c8-bec6-9c7f545a2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv(path2+'amazon(review_50_user).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88911126-1819-4a5c-bea3-137055164c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_all</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45585</td>\n",
       "      <td>987</td>\n",
       "      <td>Well worth a watch.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01 1, 2000</td>\n",
       "      <td>I've seen October Sky three times and must say...</td>\n",
       "      <td>[9, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95128</td>\n",
       "      <td>1235</td>\n",
       "      <td>A gem for the ages.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01 1, 2000</td>\n",
       "      <td>This has always been one of my favorite movies...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27036</td>\n",
       "      <td>5635</td>\n",
       "      <td>At last a Bond Girl with teeth</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>This entry has something new - besides the meg...</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120361</td>\n",
       "      <td>11376</td>\n",
       "      <td>Hackman And Coppola At Peak Performance</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>Hubby and I have seen this movie many times si...</td>\n",
       "      <td>[2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78909</td>\n",
       "      <td>9976</td>\n",
       "      <td>Where Is The Story?</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>Perhaps this is the best way to begin. Movies ...</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id                                   review  rating  \\\n",
       "0    45585       987                      Well worth a watch.     3.0   \n",
       "1    95128      1235                      A gem for the ages.     5.0   \n",
       "2    27036      5635           At last a Bond Girl with teeth     4.0   \n",
       "3   120361     11376  Hackman And Coppola At Peak Performance     5.0   \n",
       "4    78909      9976                      Where Is The Story?     2.0   \n",
       "\n",
       "  review_date                                         review_all  helpful  \n",
       "0  01 1, 2000  I've seen October Sky three times and must say...  [9, 12]  \n",
       "1  01 1, 2000  This has always been one of my favorite movies...   [1, 1]  \n",
       "2  01 1, 2001  This entry has something new - besides the meg...   [1, 1]  \n",
       "3  01 1, 2001  Hubby and I have seen this movie many times si...   [2, 5]  \n",
       "4  01 1, 2001  Perhaps this is the best way to begin. Movies ...   [1, 2]  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1777a854-01d9-41b8-925f-182815a13566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525712"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b048fad-8a18-45b6-8c26-b5a0f2153c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = rating_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "806cd8f6-6260-408e-b5df-01aac19fc8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525698"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e48636d5-5f9a-438d-9da6-848d14818925",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  16,429.    Elapsed: 0:01:35.\n",
      "  Batch   200  of  16,429.    Elapsed: 0:01:39.\n",
      "  Batch   300  of  16,429.    Elapsed: 0:01:43.\n",
      "  Batch   400  of  16,429.    Elapsed: 0:01:48.\n",
      "  Batch   500  of  16,429.    Elapsed: 0:01:52.\n",
      "  Batch   600  of  16,429.    Elapsed: 0:01:56.\n",
      "  Batch   700  of  16,429.    Elapsed: 0:02:00.\n",
      "  Batch   800  of  16,429.    Elapsed: 0:02:04.\n",
      "  Batch   900  of  16,429.    Elapsed: 0:02:09.\n",
      "  Batch 1,000  of  16,429.    Elapsed: 0:02:13.\n",
      "  Batch 1,100  of  16,429.    Elapsed: 0:02:17.\n",
      "  Batch 1,200  of  16,429.    Elapsed: 0:02:21.\n",
      "  Batch 1,300  of  16,429.    Elapsed: 0:02:25.\n",
      "  Batch 1,400  of  16,429.    Elapsed: 0:02:30.\n",
      "  Batch 1,500  of  16,429.    Elapsed: 0:02:34.\n",
      "  Batch 1,600  of  16,429.    Elapsed: 0:02:38.\n",
      "  Batch 1,700  of  16,429.    Elapsed: 0:02:42.\n",
      "  Batch 1,800  of  16,429.    Elapsed: 0:02:46.\n",
      "  Batch 1,900  of  16,429.    Elapsed: 0:02:51.\n",
      "  Batch 2,000  of  16,429.    Elapsed: 0:02:55.\n",
      "  Batch 2,100  of  16,429.    Elapsed: 0:02:59.\n",
      "  Batch 2,200  of  16,429.    Elapsed: 0:03:03.\n",
      "  Batch 2,300  of  16,429.    Elapsed: 0:03:08.\n",
      "  Batch 2,400  of  16,429.    Elapsed: 0:03:12.\n",
      "  Batch 2,500  of  16,429.    Elapsed: 0:03:16.\n",
      "  Batch 2,600  of  16,429.    Elapsed: 0:03:20.\n",
      "  Batch 2,700  of  16,429.    Elapsed: 0:03:25.\n",
      "  Batch 2,800  of  16,429.    Elapsed: 0:03:29.\n",
      "  Batch 2,900  of  16,429.    Elapsed: 0:03:33.\n",
      "  Batch 3,000  of  16,429.    Elapsed: 0:03:37.\n",
      "  Batch 3,100  of  16,429.    Elapsed: 0:03:42.\n",
      "  Batch 3,200  of  16,429.    Elapsed: 0:03:46.\n",
      "  Batch 3,300  of  16,429.    Elapsed: 0:03:50.\n",
      "  Batch 3,400  of  16,429.    Elapsed: 0:03:54.\n",
      "  Batch 3,500  of  16,429.    Elapsed: 0:03:59.\n",
      "  Batch 3,600  of  16,429.    Elapsed: 0:04:03.\n",
      "  Batch 3,700  of  16,429.    Elapsed: 0:04:07.\n",
      "  Batch 3,800  of  16,429.    Elapsed: 0:04:12.\n",
      "  Batch 3,900  of  16,429.    Elapsed: 0:04:16.\n",
      "  Batch 4,000  of  16,429.    Elapsed: 0:04:20.\n",
      "  Batch 4,100  of  16,429.    Elapsed: 0:04:24.\n",
      "  Batch 4,200  of  16,429.    Elapsed: 0:04:29.\n",
      "  Batch 4,300  of  16,429.    Elapsed: 0:04:33.\n",
      "  Batch 4,400  of  16,429.    Elapsed: 0:04:37.\n",
      "  Batch 4,500  of  16,429.    Elapsed: 0:04:41.\n",
      "  Batch 4,600  of  16,429.    Elapsed: 0:04:46.\n",
      "  Batch 4,700  of  16,429.    Elapsed: 0:04:50.\n",
      "  Batch 4,800  of  16,429.    Elapsed: 0:04:54.\n",
      "  Batch 4,900  of  16,429.    Elapsed: 0:04:59.\n",
      "  Batch 5,000  of  16,429.    Elapsed: 0:05:03.\n",
      "  Batch 5,100  of  16,429.    Elapsed: 0:05:07.\n",
      "  Batch 5,200  of  16,429.    Elapsed: 0:05:11.\n",
      "  Batch 5,300  of  16,429.    Elapsed: 0:05:16.\n",
      "  Batch 5,400  of  16,429.    Elapsed: 0:05:20.\n",
      "  Batch 5,500  of  16,429.    Elapsed: 0:05:24.\n",
      "  Batch 5,600  of  16,429.    Elapsed: 0:05:29.\n",
      "  Batch 5,700  of  16,429.    Elapsed: 0:05:33.\n",
      "  Batch 5,800  of  16,429.    Elapsed: 0:05:37.\n",
      "  Batch 5,900  of  16,429.    Elapsed: 0:05:41.\n",
      "  Batch 6,000  of  16,429.    Elapsed: 0:05:46.\n",
      "  Batch 6,100  of  16,429.    Elapsed: 0:05:50.\n",
      "  Batch 6,200  of  16,429.    Elapsed: 0:05:54.\n",
      "  Batch 6,300  of  16,429.    Elapsed: 0:05:59.\n",
      "  Batch 6,400  of  16,429.    Elapsed: 0:06:03.\n",
      "  Batch 6,500  of  16,429.    Elapsed: 0:06:07.\n",
      "  Batch 6,600  of  16,429.    Elapsed: 0:06:11.\n",
      "  Batch 6,700  of  16,429.    Elapsed: 0:06:16.\n",
      "  Batch 6,800  of  16,429.    Elapsed: 0:06:20.\n",
      "  Batch 6,900  of  16,429.    Elapsed: 0:06:24.\n",
      "  Batch 7,000  of  16,429.    Elapsed: 0:06:29.\n",
      "  Batch 7,100  of  16,429.    Elapsed: 0:06:33.\n",
      "  Batch 7,200  of  16,429.    Elapsed: 0:06:37.\n",
      "  Batch 7,300  of  16,429.    Elapsed: 0:06:42.\n",
      "  Batch 7,400  of  16,429.    Elapsed: 0:06:46.\n",
      "  Batch 7,500  of  16,429.    Elapsed: 0:06:50.\n",
      "  Batch 7,600  of  16,429.    Elapsed: 0:06:54.\n",
      "  Batch 7,700  of  16,429.    Elapsed: 0:06:59.\n",
      "  Batch 7,800  of  16,429.    Elapsed: 0:07:03.\n",
      "  Batch 7,900  of  16,429.    Elapsed: 0:07:07.\n",
      "  Batch 8,000  of  16,429.    Elapsed: 0:07:12.\n",
      "  Batch 8,100  of  16,429.    Elapsed: 0:07:16.\n",
      "  Batch 8,200  of  16,429.    Elapsed: 0:07:20.\n",
      "  Batch 8,300  of  16,429.    Elapsed: 0:07:24.\n",
      "  Batch 8,400  of  16,429.    Elapsed: 0:07:29.\n",
      "  Batch 8,500  of  16,429.    Elapsed: 0:07:33.\n",
      "  Batch 8,600  of  16,429.    Elapsed: 0:07:37.\n",
      "  Batch 8,700  of  16,429.    Elapsed: 0:07:42.\n",
      "  Batch 8,800  of  16,429.    Elapsed: 0:07:46.\n",
      "  Batch 8,900  of  16,429.    Elapsed: 0:07:50.\n",
      "  Batch 9,000  of  16,429.    Elapsed: 0:07:55.\n",
      "  Batch 9,100  of  16,429.    Elapsed: 0:07:59.\n",
      "  Batch 9,200  of  16,429.    Elapsed: 0:08:03.\n",
      "  Batch 9,300  of  16,429.    Elapsed: 0:08:08.\n",
      "  Batch 9,400  of  16,429.    Elapsed: 0:08:12.\n",
      "  Batch 9,500  of  16,429.    Elapsed: 0:08:16.\n",
      "  Batch 9,600  of  16,429.    Elapsed: 0:08:20.\n",
      "  Batch 9,700  of  16,429.    Elapsed: 0:08:25.\n",
      "  Batch 9,800  of  16,429.    Elapsed: 0:08:29.\n",
      "  Batch 9,900  of  16,429.    Elapsed: 0:08:34.\n",
      "  Batch 10,000  of  16,429.    Elapsed: 0:08:38.\n",
      "  Batch 10,100  of  16,429.    Elapsed: 0:08:42.\n",
      "  Batch 10,200  of  16,429.    Elapsed: 0:08:47.\n",
      "  Batch 10,300  of  16,429.    Elapsed: 0:08:51.\n",
      "  Batch 10,400  of  16,429.    Elapsed: 0:08:55.\n",
      "  Batch 10,500  of  16,429.    Elapsed: 0:09:00.\n",
      "  Batch 10,600  of  16,429.    Elapsed: 0:09:04.\n",
      "  Batch 10,700  of  16,429.    Elapsed: 0:09:08.\n",
      "  Batch 10,800  of  16,429.    Elapsed: 0:09:12.\n",
      "  Batch 10,900  of  16,429.    Elapsed: 0:09:17.\n",
      "  Batch 11,000  of  16,429.    Elapsed: 0:09:21.\n",
      "  Batch 11,100  of  16,429.    Elapsed: 0:09:26.\n",
      "  Batch 11,200  of  16,429.    Elapsed: 0:09:30.\n",
      "  Batch 11,300  of  16,429.    Elapsed: 0:09:34.\n",
      "  Batch 11,400  of  16,429.    Elapsed: 0:09:39.\n",
      "  Batch 11,500  of  16,429.    Elapsed: 0:09:43.\n",
      "  Batch 11,600  of  16,429.    Elapsed: 0:09:47.\n",
      "  Batch 11,700  of  16,429.    Elapsed: 0:09:54.\n",
      "  Batch 11,800  of  16,429.    Elapsed: 0:09:59.\n",
      "  Batch 11,900  of  16,429.    Elapsed: 0:10:03.\n",
      "  Batch 12,000  of  16,429.    Elapsed: 0:10:07.\n",
      "  Batch 12,100  of  16,429.    Elapsed: 0:10:12.\n",
      "  Batch 12,200  of  16,429.    Elapsed: 0:10:16.\n",
      "  Batch 12,300  of  16,429.    Elapsed: 0:10:20.\n",
      "  Batch 12,400  of  16,429.    Elapsed: 0:10:25.\n",
      "  Batch 12,500  of  16,429.    Elapsed: 0:10:29.\n",
      "  Batch 12,600  of  16,429.    Elapsed: 0:10:33.\n",
      "  Batch 12,700  of  16,429.    Elapsed: 0:10:37.\n",
      "  Batch 12,800  of  16,429.    Elapsed: 0:10:42.\n",
      "  Batch 12,900  of  16,429.    Elapsed: 0:10:46.\n",
      "  Batch 13,000  of  16,429.    Elapsed: 0:10:50.\n",
      "  Batch 13,100  of  16,429.    Elapsed: 0:10:55.\n",
      "  Batch 13,200  of  16,429.    Elapsed: 0:10:59.\n",
      "  Batch 13,300  of  16,429.    Elapsed: 0:11:03.\n",
      "  Batch 13,400  of  16,429.    Elapsed: 0:11:08.\n",
      "  Batch 13,500  of  16,429.    Elapsed: 0:11:12.\n",
      "  Batch 13,600  of  16,429.    Elapsed: 0:11:16.\n",
      "  Batch 13,700  of  16,429.    Elapsed: 0:11:21.\n",
      "  Batch 13,800  of  16,429.    Elapsed: 0:11:25.\n",
      "  Batch 13,900  of  16,429.    Elapsed: 0:11:29.\n",
      "  Batch 14,000  of  16,429.    Elapsed: 0:11:33.\n",
      "  Batch 14,100  of  16,429.    Elapsed: 0:11:38.\n",
      "  Batch 14,200  of  16,429.    Elapsed: 0:11:42.\n",
      "  Batch 14,300  of  16,429.    Elapsed: 0:11:46.\n",
      "  Batch 14,400  of  16,429.    Elapsed: 0:11:51.\n",
      "  Batch 14,500  of  16,429.    Elapsed: 0:11:55.\n",
      "  Batch 14,600  of  16,429.    Elapsed: 0:11:59.\n",
      "  Batch 14,700  of  16,429.    Elapsed: 0:12:04.\n",
      "  Batch 14,800  of  16,429.    Elapsed: 0:12:08.\n",
      "  Batch 14,900  of  16,429.    Elapsed: 0:12:12.\n",
      "  Batch 15,000  of  16,429.    Elapsed: 0:12:17.\n",
      "  Batch 15,100  of  16,429.    Elapsed: 0:12:21.\n",
      "  Batch 15,200  of  16,429.    Elapsed: 0:12:25.\n",
      "  Batch 15,300  of  16,429.    Elapsed: 0:12:30.\n",
      "  Batch 15,400  of  16,429.    Elapsed: 0:12:34.\n",
      "  Batch 15,500  of  16,429.    Elapsed: 0:12:38.\n",
      "  Batch 15,600  of  16,429.    Elapsed: 0:12:42.\n",
      "  Batch 15,700  of  16,429.    Elapsed: 0:12:47.\n",
      "  Batch 15,800  of  16,429.    Elapsed: 0:12:51.\n",
      "  Batch 15,900  of  16,429.    Elapsed: 0:12:55.\n",
      "  Batch 16,000  of  16,429.    Elapsed: 0:13:00.\n",
      "  Batch 16,100  of  16,429.    Elapsed: 0:13:04.\n",
      "  Batch 16,200  of  16,429.    Elapsed: 0:13:08.\n",
      "  Batch 16,300  of  16,429.    Elapsed: 0:13:13.\n",
      "  Batch 16,400  of  16,429.    Elapsed: 0:13:17.\n",
      "  Labeling took: 0:13:18\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "labels = test_sentence_many(model, device, tokenizer, rating_df.review)\n",
    "print(\"  Labeling took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02e373ef-def5-42f8-b803-e1b6a48a458f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525698"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee9d43e3-1fe8-4b04-a471-c19eb61172c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df['sentiment'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8d1afe0-9ab3-46e4-970b-d77d4f86d7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_all</th>\n",
       "      <th>helpful</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45585</td>\n",
       "      <td>987</td>\n",
       "      <td>Well worth a watch.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01 1, 2000</td>\n",
       "      <td>I've seen October Sky three times and must say...</td>\n",
       "      <td>[9, 12]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95128</td>\n",
       "      <td>1235</td>\n",
       "      <td>A gem for the ages.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01 1, 2000</td>\n",
       "      <td>This has always been one of my favorite movies...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27036</td>\n",
       "      <td>5635</td>\n",
       "      <td>At last a Bond Girl with teeth</td>\n",
       "      <td>4.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>This entry has something new - besides the meg...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120361</td>\n",
       "      <td>11376</td>\n",
       "      <td>Hackman And Coppola At Peak Performance</td>\n",
       "      <td>5.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>Hubby and I have seen this movie many times si...</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78909</td>\n",
       "      <td>9976</td>\n",
       "      <td>Where Is The Story?</td>\n",
       "      <td>2.0</td>\n",
       "      <td>01 1, 2001</td>\n",
       "      <td>Perhaps this is the best way to begin. Movies ...</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id                                   review  rating  \\\n",
       "0    45585       987                      Well worth a watch.     3.0   \n",
       "1    95128      1235                      A gem for the ages.     5.0   \n",
       "2    27036      5635           At last a Bond Girl with teeth     4.0   \n",
       "3   120361     11376  Hackman And Coppola At Peak Performance     5.0   \n",
       "4    78909      9976                      Where Is The Story?     2.0   \n",
       "\n",
       "  review_date                                         review_all  helpful  \\\n",
       "0  01 1, 2000  I've seen October Sky three times and must say...  [9, 12]   \n",
       "1  01 1, 2000  This has always been one of my favorite movies...   [1, 1]   \n",
       "2  01 1, 2001  This entry has something new - besides the meg...   [1, 1]   \n",
       "3  01 1, 2001  Hubby and I have seen this movie many times si...   [2, 5]   \n",
       "4  01 1, 2001  Perhaps this is the best way to begin. Movies ...   [1, 2]   \n",
       "\n",
       "   sentiment  \n",
       "0          4  \n",
       "1          4  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "51a54291-3dc7-4b08-bab3-409bebf6b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../../data/amazon/sentiment_analysis_data/'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a54e107-bce8-4cfd-9238-b7b0977a8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.to_csv('./../../data/amazon/amazon_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ff22f-871b-4b3b-bd31-82cb2cdae624",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. Pretraining 층으로만 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585187e-a749-4790-884f-11ba6e86a529",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_no_finetuning = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "# model_no_finetuning.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8a0a2-c26d-4580-8cac-f6d221d9fe4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #시작 시간 설정\n",
    "# start_time = time.time()\n",
    "\n",
    "# # 평가모드로 변경\n",
    "# model_rotten2.eval()\n",
    "\n",
    "# # 변수 초기화\n",
    "# eval_loss, eval_accuracy = 0, 0\n",
    "# nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "# for step, batch in enumerate(test_dataloader):\n",
    "#     # 경과 정보 표시\n",
    "#     if step % 100 == 0 and not step == 0:\n",
    "#         elapsed = format_time(time.time() - start_time)\n",
    "#         print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "#     # 배치를 GPU에 넣음\n",
    "#     batch = tuple(b.to(device) for b in batch)\n",
    "    \n",
    "#     # 배치에서 데이터 추출\n",
    "#     b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "#     # 그래디언트 계산 안함\n",
    "#     with torch.no_grad():     \n",
    "#         # Forward 수행\n",
    "#         outputs = model_rotten2(b_input_ids, \n",
    "#                         token_type_ids=None, \n",
    "#                         attention_mask=b_input_mask)\n",
    "    \n",
    "#     # 로스 구함\n",
    "#     logits = outputs[0]\n",
    "\n",
    "#     # CPU로 데이터 이동\n",
    "#     logits = logits.detach().cpu().numpy()\n",
    "#     label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "#     # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "#     tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "#     eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"Accuracy: {0:.2f}\".format(eval_accuracy/len(test_dataloader)))\n",
    "# print(\"Test took: {:}\".format(format_time(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb764a0-bbb7-4fc5-9ace-8326b9084a33",
   "metadata": {},
   "source": [
    "---\n",
    "### 8. 특정 영화에 대한 긍정/부정 리뷰 취합 후 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8fa982f-5a4c-47a3-a968-92539d328654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'rotten_review_scaled_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0efece-aaf1-4a64-9a28-ad8bd8290cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jordan Hoffman</td>\n",
       "      <td>False</td>\n",
       "      <td>UGO</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link       critic_name  top_critic           publisher_name  \\\n",
       "0            m/0814255      Ben McEachen       False  Sunday Mail (Australia)   \n",
       "1            m/0814255      Nick Schager       False           Slant Magazine   \n",
       "2            m/0814255  Bill Goodykoontz        True         Arizona Republic   \n",
       "3            m/0814255    Jordan Hoffman       False                      UGO   \n",
       "4            m/0814255        Mark Adams       False        Daily Mirror (UK)   \n",
       "\n",
       "  review_type  review_score review_date  \\\n",
       "0       Fresh          1.00  2010-02-09   \n",
       "1      Rotten          0.25  2010-02-10   \n",
       "2       Fresh          1.00  2010-02-10   \n",
       "3       Fresh          0.70  2010-02-10   \n",
       "4       Fresh          0.80  2010-02-10   \n",
       "\n",
       "                                      review_content  label  \n",
       "0  Whether audiences will get behind The Lightnin...      1  \n",
       "1  Harry Potter knockoffs don't come more transpa...      0  \n",
       "2  Percy Jackson isn't a great movie, but it's a ...      1  \n",
       "3                         Fun, brisk and imaginative      1  \n",
       "4  This action-packed fantasy adventure, based on...      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4732b5f-24c7-479b-ad60-d5f7451bb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df[['rotten_tomatoes_link','review_content', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8616a9cf-0bad-42f9-9d4f-1ef06a45da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>review_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fun, brisk and imaginative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link                                     review_content  \\\n",
       "0            m/0814255  Whether audiences will get behind The Lightnin...   \n",
       "1            m/0814255  Harry Potter knockoffs don't come more transpa...   \n",
       "2            m/0814255  Percy Jackson isn't a great movie, but it's a ...   \n",
       "3            m/0814255                         Fun, brisk and imaginative   \n",
       "4            m/0814255  This action-packed fantasy adventure, based on...   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "73d5b07d-0fad-4417-bcb5-dd42a17ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_review = df_review.pivot_table(index='rotten_tomatoes_link', columns='label', aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c362eef3-ca3d-42e1-ae60-6487366e2a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m/+_one_2019</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/+h</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/-_man</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/-cule_valley_of_the_lost_ants</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/0814255</th>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zoom_2006</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zootopia</th>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zorba_the_greek</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zulu</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m/zulu_dawn</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16933 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                review_content     \n",
       "label                                        0    1\n",
       "rotten_tomatoes_link                               \n",
       "m/+_one_2019                                 0   33\n",
       "m/+h                                         2    2\n",
       "m/-_man                                      1    3\n",
       "m/-cule_valley_of_the_lost_ants              0    5\n",
       "m/0814255                                   12   34\n",
       "...                                        ...  ...\n",
       "m/zoom_2006                                 22    3\n",
       "m/zootopia                                   2  166\n",
       "m/zorba_the_greek                            0    3\n",
       "m/zulu                                       0    4\n",
       "m/zulu_dawn                                  0    3\n",
       "\n",
       "[16933 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8d1a985e-9f24-4102-8806-64213ae930c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                label\n",
       "review_content  0        12\n",
       "                1        34\n",
       "Name: m/0814255, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review.loc['m/0814255']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "db134566-29a3-4856-89db-ba490ba0bb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                label\n",
       "review_content  0        48\n",
       "                1        12\n",
       "Name: m/10000_bc, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_review.loc['m/10000_bc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75839b-ae10-4c73-b238-96ebe59d3b8e",
   "metadata": {},
   "source": [
    "- Movie1: 'm/0814255'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87a5547a-85dd-4f14-a25a-29e9675f60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정, 부정 리뷰들을 취합 후 파일저장\n",
    "def movie_sentiment_filter(df, movie_link, file_name):\n",
    "    condition = df['rotten_tomatoes_link'] == movie_link\n",
    "    df = df[condition]\n",
    "    \n",
    "    pos_review_list = df[df['label'] == 1].reset_index(drop=True).review_content\n",
    "    movie1_pos = \" \".join(pos_review_list)\n",
    "    \n",
    "    neg_review_list = df[df['label'] == 0].reset_index(drop=True).review_content\n",
    "    movie1_neg = \" \".join(neg_review_list)\n",
    "    \n",
    "    f = open(path + f\"{file_name}_pos.txt\", 'w')\n",
    "    f.write(movie1_pos)\n",
    "    f.close()\n",
    "    \n",
    "    f = open(path + f\"{file_name}_neg.txt\", 'w')\n",
    "    f.write(movie1_neg)\n",
    "    f.close()\n",
    "    \n",
    "    print(f\"{file_name}_pos/neg save finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3b07188-91f8-489e-ac06-d0a4003ef8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie1_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/0814255', file_name='movie1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e825ec1e-ad86-4639-8bcb-093b3f797eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie2_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/0878835', file_name='movie2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d912b320-11fc-4aac-b174-8aba8a4cfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie3_pos/neg save finish!!\n"
     ]
    }
   ],
   "source": [
    "movie_sentiment_filter(df=df_review, movie_link='m/10000_bc', file_name='movie3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b536f-2777-46eb-a04b-23204028994d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
